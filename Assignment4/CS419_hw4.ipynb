{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83aUtzAmywgV",
        "outputId": "754b257e-2106-4109-d286-2640c22b2f4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "g3uXL_3XkmU1"
      },
      "outputs": [],
      "source": [
        "from skimage.feature import local_binary_pattern\n",
        "from skimage.feature import graycomatrix, graycoprops\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "import glob"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMn1ioFBpOVI"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGwMcM2RK7LS"
      },
      "source": [
        "# Download Images\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PLnmMYOpih4",
        "outputId": "e4f1cc6d-3910-48cf-9fa1-3b27bf002b18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "480 4320 4320\n"
          ]
        }
      ],
      "source": [
        "#Downlaod images from drive/MyDrive/CS419/Outex_TC_00012\n",
        "\n",
        "\"\"\"\n",
        "source_dir = '/content/drive/MyDrive/CS419/Assignment4/Outex_TC_00012'\n",
        "images_dir = '/content/drive/MyDrive/CS419/Assignment4/Outex_TC_00012/images'\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "images_dir = './imageset/images/'\n",
        "\n",
        "\n",
        "train_0 = []\n",
        "test_0 = []\n",
        "test_1 = []\n",
        "\n",
        "filenames = os.listdir(images_dir)\n",
        "\n",
        "#sort filenames to correctly match the labels\n",
        "filenames.sort()\n",
        "#print(filenames)\n",
        "\n",
        "#read images\n",
        "for i in range(480):\n",
        "  image = cv2.imread(os.path.join(images_dir, filenames[i]), cv2.IMREAD_GRAYSCALE)\n",
        "  train_0.append(image)\n",
        "\n",
        "for i in range(480, 4800):\n",
        "  test_0.append(cv2.imread(os.path.join(images_dir, filenames[i]), cv2.IMREAD_GRAYSCALE))\n",
        "\n",
        "for i in range(4800, len(filenames)):\n",
        "  test_1.append(cv2.imread(os.path.join(images_dir, filenames[i]), cv2.IMREAD_GRAYSCALE))\n",
        "\n",
        "print(len(train_0), len(test_0), len(test_1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "u_2TLpTun2CH",
        "outputId": "393d5740-1c50-4de1-d2e9-a27beba53122"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(480, 128, 128) (4320, 128, 128) (4320, 128, 128)\n"
          ]
        }
      ],
      "source": [
        "#converting lists to arrays and checking the shape\n",
        "\n",
        "train_0 = np.array(train_0)\n",
        "test_0 = np.array(test_0)\n",
        "test_1 = np.array(test_1)\n",
        "print(train_0.shape, test_0.shape, test_1.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_45apZrMkeNO"
      },
      "source": [
        "# Feature Extractors\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvNUG9m8kVb5"
      },
      "source": [
        "### 1.Local Binary Patterns (LBP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "nbUXA8asbyKq"
      },
      "outputs": [],
      "source": [
        "def compute_lbp(image, radius=2, n_points=16, method='uniform'):\n",
        "  \"\"\"\n",
        "  Compute Local Binary Pattern (LBP) of an image.\n",
        "\n",
        "  Args:\n",
        "    image: Grayscale input image.\n",
        "    radius: Radius of the circular neighborhood.\n",
        "    n_points: Number of points in the neighborhood.\n",
        "    method: Method to compute LBP ('uniform' or 'default').\n",
        "\n",
        "  Returns:\n",
        "    LBP histogram (feature vector).\n",
        "  \"\"\"\n",
        "  lbp = local_binary_pattern(image, n_points, radius, method)\n",
        "  # Histogram of LBP\n",
        "  n_bins = int(lbp.max() + 1)\n",
        "  hist, _ = np.histogram(lbp.ravel(), bins=n_bins, range=(0, n_bins))\n",
        "  hist = hist / hist.sum()  # Normalize histogram\n",
        "  hist = np.array(hist)\n",
        "  return hist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEmeatHhk_yd"
      },
      "source": [
        "### 2. GLCM (Gray-Level Co-occurrence Matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "8yprjoRZlE6R"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1.29297244e+02 2.00602393e+02 1.19780758e+02 2.51701593e+02\n",
            " 3.52921193e+02 2.00602393e+02 3.33189608e+02 2.51701593e+02\n",
            " 5.03768250e+02 4.72101600e+02 4.62945312e+02 5.53210066e+02\n",
            " 8.38477600e-01 7.49415698e-01 8.50319813e-01 6.85574989e-01\n",
            " 5.60106520e-01 7.49415698e-01 5.84182054e-01 6.85574989e-01\n",
            " 3.72317450e-01 4.12329148e-01 4.23398444e-01 3.11352291e-01\n",
            " 2.16116038e-02 1.94366186e-02 2.18652359e-02 1.87320424e-02\n",
            " 1.77923841e-02 1.94366186e-02 1.78587575e-02 1.87320424e-02\n",
            " 1.69425730e-02 1.69218481e-02 1.69893694e-02 1.66313788e-02\n",
            " 1.02688617e-01 7.98704550e-02 1.10413555e-01 7.68038696e-02\n",
            " 6.63750650e-02 7.98704550e-02 6.86084034e-02 7.68038696e-02\n",
            " 5.57158519e-02 5.45557389e-02 5.84547817e-02 5.19947098e-02\n",
            " 9.05351870e+00 1.14906070e+01 8.69525098e+00 1.27577035e+01\n",
            " 1.49519469e+01 1.14906070e+01 1.45932540e+01 1.27577035e+01\n",
            " 1.78196250e+01 1.75738851e+01 1.72329375e+01 1.89007937e+01]\n"
          ]
        }
      ],
      "source": [
        "# Compute GLCM and extract features\n",
        "def compute_glcm_features(gray_image, distances, angles):\n",
        "  glcm = graycomatrix(\n",
        "    gray_image,\n",
        "    distances=distances,\n",
        "    angles=angles,\n",
        "    levels=256,  # 8-bit image has 256 levels\n",
        "    symmetric=True,\n",
        "    normed=True\n",
        "  )\n",
        "\n",
        "  # Extract features\n",
        "  contrast = graycoprops(glcm, 'contrast')\n",
        "  dissimilarity = graycoprops(glcm, 'dissimilarity')\n",
        "  homogeneity = graycoprops(glcm, 'homogeneity')\n",
        "  energy = graycoprops(glcm, 'energy')\n",
        "  correlation = graycoprops(glcm, 'correlation')\n",
        "\n",
        "  features = {\n",
        "    'Contrast': contrast,\n",
        "    'Correlation': correlation,\n",
        "    'Energy': energy,\n",
        "    'Homogeneity': homogeneity,\n",
        "    'Dissimilarity': dissimilarity\n",
        "  }\n",
        "\n",
        "  feature_vector = []\n",
        "  #how to initialize an empyt numpy array\n",
        "\n",
        "\n",
        "  for key, value in features.items():\n",
        "    for v in value:\n",
        "      for k in v:\n",
        "        feature_vector.append(k)\n",
        "\n",
        "  feature_vector = np.array(feature_vector)\n",
        "\n",
        "  return glcm, feature_vector\n",
        "\n",
        "\n",
        "distances = [1, 2, 3]  # Pixel distances\n",
        "angles = [0, np.pi/4, np.pi/2, 3*np.pi/4]  # Angles in radians\n",
        "\n",
        "print(compute_glcm_features(train_0[0], distances, angles)[1])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6cqr8WUAptE"
      },
      "source": [
        "### 3. FFT Features of the Texture Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ljuavzqADFFZ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FFT Features: [7528569.57085799 7764039.4722744  3294343.46178634 1309487.60913622\n",
            "  155390.19115493 4318971.59726571 1880077.63356567 2656243.32990535\n",
            " 2206772.5047341  2233002.00015262 1890703.22069978 2670094.91703946\n",
            " 2195994.10184718]\n"
          ]
        }
      ],
      "source": [
        "def compute_fft_features(image, num_rings=5, num_wedges=8):\n",
        "  # Compute FFT and shift zero frequency to center\n",
        "  fft = np.fft.fft2(image)\n",
        "  fft_shifted = np.fft.fftshift(fft)\n",
        "  magnitude_spectrum = np.abs(fft_shifted)\n",
        "\n",
        "  # Get image dimensions and center\n",
        "  h, w = image.shape\n",
        "  cy, cx = h // 2, w // 2\n",
        "  max_radius = int(np.sqrt(cy**2 + cx**2))\n",
        "\n",
        "  # Create radius and angle maps\n",
        "  y, x = np.ogrid[:h, :w]\n",
        "  radius = np.sqrt((y - cy)**2 + (x - cx)**2)\n",
        "  angle = np.arctan2(y - cy, x - cx) % (2 * np.pi)\n",
        "\n",
        "  # Compute ring features\n",
        "  ring_edges = np.linspace(0, max_radius, num_rings + 1)\n",
        "  ring_features = [\n",
        "    magnitude_spectrum[(radius >= ring_edges[i]) & (radius < ring_edges[i + 1])].sum()\n",
        "    for i in range(num_rings)\n",
        "  ]\n",
        "\n",
        "  # Compute wedge features\n",
        "  wedge_edges = np.linspace(0, 2 * np.pi, num_wedges + 1)\n",
        "  wedge_features = [\n",
        "    magnitude_spectrum[(angle >= wedge_edges[i]) & (angle < wedge_edges[i + 1])].sum()\n",
        "    for i in range(num_wedges)\n",
        "  ]\n",
        "\n",
        "  # Flatten features by concatenating ring and wedge features\n",
        "  flattened_features = np.array(ring_features + wedge_features)\n",
        "\n",
        "  return flattened_features\n",
        "\n",
        "image = train_0[0]\n",
        "\n",
        "# Extract FFT features\n",
        "num_rings = 5  # Number of rings\n",
        "num_wedges = 8  # Number of wedges\n",
        "fft_features = compute_fft_features(image, num_rings, num_wedges)\n",
        "\n",
        "# Visualize features\n",
        "print(\"FFT Features:\", fft_features)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmaZTYfgDJ59"
      },
      "source": [
        "### 4. Gabor Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Oi397PG_DNqA"
      },
      "outputs": [],
      "source": [
        "def extract_gabor_features(image, ksize=25, sigma=5.0, lambd=5.0, gamma=0.5, psi=0, orientations=None):\n",
        "    \"\"\"\n",
        "    Extract flattened Gabor features from an image using multiple orientations.\n",
        "\n",
        "    Args:\n",
        "        image_path (str): Path to the grayscale image.\n",
        "        ksize (int): Size of the Gabor filter kernel.\n",
        "        sigma (float): Standard deviation of the Gaussian envelope.\n",
        "        lambd (float): Wavelength of the sinusoidal factor.\n",
        "        gamma (float): Aspect ratio.\n",
        "        psi (float): Phase offset.\n",
        "        orientations (list): List of orientations in radians. Defaults to [0, π/4, π/2, 3π/4].\n",
        "\n",
        "    Returns:\n",
        "        flattened_features (np.ndarray): Flattened feature vector (mean and std for each orientation).\n",
        "        filtered_images (list): List of filtered images for each orientation.\n",
        "        kernels (list): List of Gabor filter kernels for each orientation.\n",
        "    \"\"\"\n",
        "    if orientations is None:\n",
        "        orientations = [0, np.pi / 4, np.pi / 2, 3 * np.pi / 4]  # Default orientations\n",
        "\n",
        "    # Lists to store results\n",
        "    filtered_images = []\n",
        "    kernels = []\n",
        "    gabor_features = []\n",
        "\n",
        "    # Apply Gabor filters for each orientation\n",
        "    for theta in orientations:\n",
        "        # Create Gabor kernel\n",
        "        kernel = cv2.getGaborKernel((ksize, ksize), sigma, theta, lambd, gamma, psi, ktype=cv2.CV_32F)\n",
        "        filtered = cv2.filter2D(image, cv2.CV_8UC3, kernel)\n",
        "        mean = filtered.mean()\n",
        "        std = filtered.std()\n",
        "        gabor_features.append(mean)\n",
        "        gabor_features.append(std)\n",
        "        filtered_images.append(filtered)\n",
        "        kernels.append(kernel)\n",
        "\n",
        "    gabor_features = np.array(gabor_features)\n",
        "\n",
        "    return gabor_features, filtered_images, kernel\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Create Feature Vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set:\n",
            "LBP features: [[0.0390625  0.06884766 0.07946777 ... 0.05950928 0.04534912 0.08459473]\n",
            " [0.03656006 0.06652832 0.07897949 ... 0.05786133 0.04614258 0.08312988]\n",
            " [0.03796387 0.06463623 0.07635498 ... 0.06256104 0.04608154 0.08032227]\n",
            " ...\n",
            " [0.02905273 0.05853271 0.05255127 ... 0.05548096 0.05786133 0.09222412]\n",
            " [0.02990723 0.05194092 0.05706787 ... 0.05108643 0.04754639 0.0880127 ]\n",
            " [0.02862549 0.05462646 0.05834961 ... 0.05310059 0.05224609 0.08618164]]\n",
            "GLCM features: [[1.29297244e+02 8.38477600e-01 2.16116038e-02 1.02688617e-01\n",
            "  9.05351870e+00]\n",
            " [1.31487574e+02 8.36293752e-01 2.21286177e-02 1.09489919e-01\n",
            "  9.08882874e+00]\n",
            " [1.58203740e+02 8.03225950e-01 2.29071629e-02 9.44713035e-02\n",
            "  1.00690207e+01]\n",
            " ...\n",
            " [4.92589813e+01 9.38525276e-01 4.04948876e-02 2.16220782e-01\n",
            "  5.10433071e+00]\n",
            " [6.67017101e+01 9.16687417e-01 4.29720194e-02 1.78639433e-01\n",
            "  6.13096703e+00]\n",
            " [6.54130782e+01 9.18076357e-01 4.54018728e-02 1.94486012e-01\n",
            "  5.94408219e+00]]\n",
            "FFT features: [[7528569.57085799 7764039.4722744  3294343.46178634 ... 1890703.22069978\n",
            "  2670094.91703946 2195994.10184718]\n",
            " [7927406.44610523 7448431.2015882  3009821.46628941 ... 1980340.29031769\n",
            "  2457224.04197245 2162586.81356739]\n",
            " [7645606.16629697 8228487.52835925 3139597.61132751 ... 2023512.25822089\n",
            "  2410952.8656009  2149260.0004668 ]\n",
            " ...\n",
            " [8833913.51187849 3987081.91397701 1901711.69379565 ... 1639443.50325486\n",
            "  1682261.51182506 1691159.7149659 ]\n",
            " [9547745.45809901 4737197.9256229  2165306.41799381 ... 1949425.30432612\n",
            "  2013243.40792925 1809524.32523164]\n",
            " [9309571.41762775 5081979.28494645 2179480.66567473 ... 1953014.94333586\n",
            "  2108562.40283696 1984980.48054556]]\n",
            "Gabor features: [[105.28106689 110.97929029 102.65063477 ... 104.93249783 105.24108887\n",
            "  104.19217993]\n",
            " [107.39556885 110.43939379 100.72229004 ... 105.48301976 106.03594971\n",
            "  105.80891032]\n",
            " [107.32904053 114.34326723 102.86779785 ... 104.57660708 103.41320801\n",
            "  102.65481193]\n",
            " ...\n",
            " [ 81.65557861  84.40168973  88.25335693 ...  66.38490928  89.62200928\n",
            "   79.41228059]\n",
            " [ 83.9196167   87.33841775  91.55603027 ...  77.43449978  91.2076416\n",
            "   82.6999809 ]\n",
            " [ 84.65386963  88.55421506  95.46875    ...  89.65454826  93.95513916\n",
            "   89.34786384]]\n",
            "\n",
            "Test set 0:\n",
            "LBP features: [[0.03881836 0.07263184 0.07318115 ... 0.06005859 0.05218506 0.09008789]\n",
            " [0.03649902 0.07263184 0.07000732 ... 0.06304932 0.04937744 0.08563232]\n",
            " [0.03515625 0.07214355 0.07116699 ... 0.06427002 0.05047607 0.08557129]\n",
            " ...\n",
            " [0.02862549 0.05285645 0.0512085  ... 0.05670166 0.05749512 0.09552002]\n",
            " [0.03204346 0.05950928 0.046875   ... 0.06182861 0.07073975 0.09863281]\n",
            " [0.03149414 0.06182861 0.05126953 ... 0.06402588 0.0715332  0.10754395]]\n",
            "GLCM features: [[1.51084031e+02 8.12225435e-01 3.11642386e-02 1.01617060e-01\n",
            "  9.74643209e+00]\n",
            " [1.41935101e+02 8.23480757e-01 3.06509275e-02 1.09925554e-01\n",
            "  9.40594242e+00]\n",
            " [1.65647330e+02 7.93910484e-01 3.13676032e-02 9.83683527e-02\n",
            "  1.02397269e+01]\n",
            " ...\n",
            " [6.45356176e+01 9.19403114e-01 5.26309018e-02 1.99415752e-01\n",
            "  5.85783711e+00]\n",
            " [5.55651452e+01 9.30308588e-01 6.58816430e-02 2.23441940e-01\n",
            "  5.38933317e+00]\n",
            " [6.64768086e+01 9.17210548e-01 6.74226770e-02 2.12412778e-01\n",
            "  5.99452510e+00]]\n",
            "FFT features: [[7386428.96383847 7358877.61564776 3272827.21503438 ... 1730581.225829\n",
            "  2448786.44820847 2188446.41398875]\n",
            " [7615482.37030542 6893229.54186048 2941841.16311191 ... 1769756.71234864\n",
            "  2265494.49166579 2078140.87694716]\n",
            " [7380258.77560203 7438387.89051482 3024915.40736908 ... 1759783.33342935\n",
            "  2160891.05129779 2056665.65789969]\n",
            " ...\n",
            " [9466081.97416367 4444541.76015777 2005277.70888322 ... 1892555.92693452\n",
            "  1903023.26318861 1801189.82576969]\n",
            " [9169120.60783402 4534824.39686784 2206160.81299721 ... 1949217.81454714\n",
            "  1964358.51682552 1939032.106046  ]\n",
            " [9425471.80853942 4961335.17031129 2477449.75628531 ... 2197176.7480548\n",
            "  2175155.09936697 2037917.83551101]]\n",
            "Gabor features: [[111.92803955 116.29999507  99.76239014 ... 102.27053591 103.49133301\n",
            "  101.73447122]\n",
            " [112.40625    114.32804012  97.68206787 ... 102.96214896 103.78063965\n",
            "  102.21203166]\n",
            " [112.03393555 117.86881713  99.46032715 ... 100.02944503 100.67437744\n",
            "   98.59710765]\n",
            " ...\n",
            " [ 82.29345703  85.65533188  91.90002441 ...  83.86771211  90.53656006\n",
            "   81.53760175]\n",
            " [ 78.72625732  79.63783044  92.85314941 ...  83.81008491  91.41265869\n",
            "   84.34726939]\n",
            " [ 81.00567627  83.56779185  91.60028076 ...  88.82673727  96.85644531\n",
            "   92.27016367]]\n",
            "\n",
            "Test set 1:\n",
            "LBP features: [[0.04211426 0.0723877  0.07177734 ... 0.0637207  0.05316162 0.09320068]\n",
            " [0.03985596 0.07562256 0.07348633 ... 0.0657959  0.05194092 0.09338379]\n",
            " [0.03790283 0.07531738 0.07336426 ... 0.06671143 0.05352783 0.0916748 ]\n",
            " ...\n",
            " [0.03234863 0.05609131 0.05432129 ... 0.05859375 0.06079102 0.0980835 ]\n",
            " [0.03356934 0.05969238 0.04962158 ... 0.06451416 0.07165527 0.10406494]\n",
            " [0.03338623 0.06115723 0.05206299 ... 0.06500244 0.07232666 0.1083374 ]]\n",
            "GLCM features: [[1.51104331e+02 8.10485373e-01 3.11224396e-02 1.03063521e-01\n",
            "  9.69611220e+00]\n",
            " [1.43309301e+02 8.21784940e-01 3.03147834e-02 1.07695917e-01\n",
            "  9.41547736e+00]\n",
            " [1.67126907e+02 7.92037834e-01 3.10319665e-02 9.74911148e-02\n",
            "  1.02648253e+01]\n",
            " ...\n",
            " [6.61616019e+01 9.17247304e-01 5.34345277e-02 1.95704095e-01\n",
            "  5.91898376e+00]\n",
            " [5.68566068e+01 9.28736495e-01 6.45293013e-02 2.20461034e-01\n",
            "  5.47336368e+00]\n",
            " [6.67252707e+01 9.16448180e-01 6.60961737e-02 2.07039226e-01\n",
            "  6.01636319e+00]]\n",
            "FFT features: [[7269908.74338964 7595112.59912016 3616519.34309731 ... 1896722.04897796\n",
            "  2550371.43583834 2130528.4101198 ]\n",
            " [7518902.66419507 7163961.55394691 3314236.57416979 ... 1932752.68138343\n",
            "  2390625.2348563  2070972.85892371]\n",
            " [7284759.97235656 7739944.61186429 3441459.99170794 ... 1915365.35567677\n",
            "  2319703.77116851 2076865.17332172]\n",
            " ...\n",
            " [9410991.02040217 4603077.60694608 2159436.57840368 ... 1926196.05213606\n",
            "  1961870.8966461  1820475.28442632]\n",
            " [9161847.32256236 4505038.44886051 2268167.01730933 ... 1962641.92248665\n",
            "  1955869.78320946 1952962.41769104]\n",
            " [9391572.04159829 4958810.63482004 2527995.73810285 ... 2223495.81262683\n",
            "  2167719.59063647 2018494.62999096]]\n",
            "Gabor features: [[110.42382812 115.15850387 102.3291626  ... 103.53699715 103.23504639\n",
            "  101.564542  ]\n",
            " [109.85400391 113.66491731  99.10906982 ... 105.92027517 104.13458252\n",
            "  103.05739209]\n",
            " [112.08789062 116.38000686 100.92498779 ... 103.48687392 101.52770996\n",
            "   99.87816046]\n",
            " ...\n",
            " [ 82.53173828  85.98661434  93.06982422 ...  83.90912048  90.82617188\n",
            "   82.35681412]\n",
            " [ 78.68310547  80.67916841  93.065979   ...  81.33539377  91.65496826\n",
            "   84.49938695]\n",
            " [ 82.43511963  84.20383935  91.58813477 ...  87.34444626  96.43994141\n",
            "   91.80783874]]\n",
            "\n",
            "Shapes:\n",
            "Training set: (480, 10), (480, 5), (480, 13), (480, 8)\n",
            "Test set 0: (4320, 10), (4320, 5), (4320, 13), (4320, 8)\n",
            "Test set 1: (4320, 10), (4320, 5), (4320, 13), (4320, 8)\n"
          ]
        }
      ],
      "source": [
        "# Initialize dictionaries to store feature vectors for training and test sets\n",
        "train = {}\n",
        "test_0_dict = {}\n",
        "test_1_dict = {}\n",
        "\n",
        "# Define distances and angles for GLCM computation\n",
        "distances = [1, 2, 3]  # Pixel distances\n",
        "angles = [0, np.pi/4, np.pi/2, 3*np.pi/4]  # Angles in radians\n",
        "\n",
        "# Initialize lists to store feature vectors\n",
        "lbp = []\n",
        "glcm = []\n",
        "fft = []\n",
        "gabor = []\n",
        "\n",
        "# Compute features for training images\n",
        "for image in train_0:\n",
        "    lbp.append(compute_lbp(image))  # Compute LBP features\n",
        "    _, image_features = compute_glcm_features(image, distances, angles)\n",
        "    glcm.append(image_features)  # Compute GLCM features\n",
        "    fft.append(compute_fft_features(image))  # Compute FFT features\n",
        "    flattened_features, _, _ = extract_gabor_features(image)  # Compute Gabor features\n",
        "    gabor.append(flattened_features)  # Compute Gabor features\n",
        "\n",
        "# Store computed features in the training dictionary\n",
        "train[\"LBP\"] = np.array(lbp)\n",
        "train[\"GLCM\"] = np.array(glcm)\n",
        "train[\"FFT\"] = np.array(fft)\n",
        "train[\"Gabor\"] = np.array(gabor)\n",
        "\n",
        "# Reset feature lists for test_0\n",
        "lbp0 = []\n",
        "glcm0 = []\n",
        "fft0 = []\n",
        "gabor0 = []\n",
        "\n",
        "# Compute features for test_0 images\n",
        "for i, image in enumerate(test_0):\n",
        "    lbp0.append(compute_lbp(image))  # Compute LBP features\n",
        "    _, image_features = compute_glcm_features(image, distances, angles)\n",
        "    glcm0.append(image_features)  # Compute GLCM features\n",
        "    fft0.append(compute_fft_features(image))  # Compute FFT features\n",
        "    flattened_features, _, _ = extract_gabor_features(image)  # Compute Gabor features\n",
        "    gabor0.append(flattened_features)  # Compute Gabor features\n",
        "\n",
        "# Store computed features in the test_0 dictionary\n",
        "test_0_dict[\"LBP\"] = np.array(lbp0)\n",
        "test_0_dict[\"GLCM\"] = np.array(glcm0)\n",
        "test_0_dict[\"FFT\"] = np.array(fft0)\n",
        "test_0_dict[\"Gabor\"] = np.array(gabor0)\n",
        "\n",
        "# Reset feature lists for test_1\n",
        "lbp1 = []\n",
        "glcm1 = []\n",
        "fft1 = []\n",
        "gabor1 = []\n",
        "\n",
        "# Compute features for test_1 images\n",
        "for image in test_1:\n",
        "    lbp1.append(compute_lbp(image))  # Compute LBP features\n",
        "    _, image_features = compute_glcm_features(image, distances, angles)\n",
        "    glcm1.append(image_features)  # Compute GLCM features\n",
        "    fft1.append(compute_fft_features(image))  # Compute FFT features\n",
        "    flattened_features, _, _ = extract_gabor_features(image)  # Compute Gabor features\n",
        "    gabor1.append(flattened_features)  # Compute Gabor features\n",
        "\n",
        "# Store computed features in the test_1 dictionary\n",
        "test_1_dict[\"LBP\"] = np.array(lbp1)\n",
        "test_1_dict[\"GLCM\"] = np.array(glcm1)\n",
        "test_1_dict[\"FFT\"] = np.array(fft1)\n",
        "test_1_dict[\"Gabor\"] = np.array(gabor1)\n",
        "\n",
        "\n",
        "print(\"Training set:\")\n",
        "print(\"LBP features:\", train[\"LBP\"])\n",
        "print(\"GLCM features:\", train[\"GLCM\"])\n",
        "print(\"FFT features:\", train[\"FFT\"])\n",
        "print(\"Gabor features:\", train[\"Gabor\"])\n",
        "\n",
        "print(\"\\nTest set 0:\")\n",
        "print(\"LBP features:\", test_0_dict[\"LBP\"])\n",
        "print(\"GLCM features:\", test_0_dict[\"GLCM\"])\n",
        "print(\"FFT features:\", test_0_dict[\"FFT\"])\n",
        "print(\"Gabor features:\", test_0_dict[\"Gabor\"])\n",
        "\n",
        "print(\"\\nTest set 1:\")\n",
        "\n",
        "print(\"LBP features:\", test_1_dict[\"LBP\"])\n",
        "print(\"GLCM features:\", test_1_dict[\"GLCM\"])\n",
        "print(\"FFT features:\", test_1_dict[\"FFT\"])\n",
        "print(\"Gabor features:\", test_1_dict[\"Gabor\"])\n",
        "\n",
        "print(\"\\nShapes:\")\n",
        "print(f\"Training set: {train['LBP'].shape}, {train['GLCM'].shape}, {train['FFT'].shape}, {train['Gabor'].shape}\")\n",
        "print(f\"Test set 0: {test_0_dict['LBP'].shape}, {test_0_dict['GLCM'].shape}, {test_0_dict['FFT'].shape}, {test_0_dict['Gabor'].shape}\")\n",
        "print(f\"Test set 1: {test_1_dict['LBP'].shape}, {test_1_dict['GLCM'].shape}, {test_1_dict['FFT'].shape}, {test_1_dict['Gabor'].shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(480, 10) (480, 5) (480, 13)\n"
          ]
        }
      ],
      "source": [
        "print(train[\"LBP\"].shape, test_0_dict[\"GLCM\"].shape, test_1_dict[\"FFT\"].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Distance Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "def euclidean_distance(x, y):\n",
        "    \"\"\"\n",
        "    Compute the Euclidean distance between two feature vectors.\n",
        "\n",
        "    Args:\n",
        "        x: Feature vector 1 (1D array).\n",
        "        y: Feature vector 2 (1D array).\n",
        "\n",
        "    Returns:\n",
        "        Euclidean distance (float).\n",
        "    \"\"\"\n",
        "    return np.sqrt(np.sum((x - y) ** 2))\n",
        "\n",
        "\n",
        "def manhattan_distance(x, y):\n",
        "    \"\"\"\n",
        "    Compute the Manhattan distance between two feature vectors.\n",
        "\n",
        "    Args:\n",
        "        x: Feature vector 1 (1D array).\n",
        "        y: Feature vector 2 (1D array).\n",
        "\n",
        "    Returns:\n",
        "        Manhattan distance (float).\n",
        "    \"\"\"\n",
        "    return np.sum(np.abs(x - y))\n",
        "\n",
        "\n",
        "def chi_squared_distance(x, y, epsilon=1e-10):\n",
        "    \"\"\"\n",
        "    Compute the Chi-squared distance between two feature vectors.\n",
        "\n",
        "    Args:\n",
        "        x: Feature vector 1 (1D array).\n",
        "        y: Feature vector 2 (1D array).\n",
        "        epsilon: Small constant to avoid division by zero (default: 1e-10).\n",
        "\n",
        "    Returns:\n",
        "        Chi-squared distance (float).\n",
        "    \"\"\"\n",
        "    return np.sum((x - y) ** 2 / (x + y + epsilon))\n",
        "\n",
        "\n",
        "def compute_inverse_covariance_matrix(train_features):\n",
        "    \"\"\"\n",
        "    Compute the regularized inverse covariance matrix.\n",
        "\n",
        "    Args:\n",
        "        train_features (np.ndarray): Feature vectors of training data.\n",
        "\n",
        "    Returns:\n",
        "        inv_cov_matrix (np.ndarray): Regularized inverse covariance matrix.\n",
        "    \"\"\"\n",
        "    # Compute the covariance matrix\n",
        "    cov_matrix = np.cov(train_features, rowvar=False)\n",
        "    \n",
        "    # Add a small regularization term to the diagonal\n",
        "    regularization_term = 1e-5  # Adjust this value if needed\n",
        "    cov_matrix += np.eye(cov_matrix.shape[0]) * regularization_term\n",
        "    \n",
        "    # Compute the inverse\n",
        "    inv_cov_matrix = np.linalg.inv(cov_matrix)\n",
        "    return inv_cov_matrix\n",
        "\n",
        "\n",
        "\n",
        "def mahalanobis_distance(x, y, inv_cov_matrix):\n",
        "    \"\"\"\n",
        "    Compute the Mahalanobis distance between two feature vectors.\n",
        "\n",
        "    Args:\n",
        "        x: Feature vector 1 (1D array).\n",
        "        y: Feature vector 2 (1D array).\n",
        "        inv_cov_matrix: Inverse covariance matrix of the training data.\n",
        "\n",
        "    Returns:\n",
        "        Mahalanobis distance (float).\n",
        "    \"\"\"\n",
        "    diff = x - y\n",
        "    return np.sqrt(np.dot(np.dot(diff.T, inv_cov_matrix), diff))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Nearest Neighbour Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "t6FnOnHjeM0B"
      },
      "outputs": [],
      "source": [
        "def nearest_neighbour(train_feature_vector : np.ndarray, train_labels : np.ndarray, test_feature_vectors : np.ndarray, metric = \"Euclidean\"):\n",
        "    \"\"\"\n",
        "        Perform Nearest Neighbor classification with k=1.\n",
        "\n",
        "        Args:\n",
        "            train_feature_vector: Feature vectors of training samples (2D array).\n",
        "            train_labels: Labels of training samples (1D array).\n",
        "            test_feature_vectors: Feature vectors of test samples (2D array).\n",
        "            metric: Distance metric to use ('euclidean', 'manhattan', 'chi_squared', 'mahalanobis').\n",
        "\n",
        "        Returns:\n",
        "            Predicted labels for the test samples.\n",
        "    \"\"\"\n",
        "\n",
        "    test_x_len, _ = test_feature_vectors.shape\n",
        "    train_x_len, _ = train_feature_vector.shape\n",
        "\n",
        "    y_predict = np.zeros(test_x_len, dtype=int)\n",
        "\n",
        "    if metric == \"Euclidean\":\n",
        "        \n",
        "        for i in range(test_x_len):\n",
        "\n",
        "            x_test = test_feature_vectors[i]\n",
        "\n",
        "            neighbours = np.zeros(1)\n",
        "\n",
        "            euclidean_distances = np.zeros(train_x_len, np.float32)\n",
        "\n",
        "            for j in range(train_x_len):\n",
        "                \n",
        "                distance = euclidean_distance(x_test, train_feature_vector[j])\n",
        "\n",
        "                euclidean_distances[j] = distance\n",
        "\n",
        "            inds = euclidean_distances.argsort() \n",
        "          \n",
        "            Y_train_sorted = train_labels[inds] \n",
        "\n",
        "            neighbours = Y_train_sorted[0]\n",
        "\n",
        "\n",
        "            y_predict[i] = neighbours\n",
        "\n",
        "\n",
        "    \n",
        "    elif metric == \"Manhattan\":\n",
        "        for i in range(test_x_len):\n",
        "\n",
        "            x_test = test_feature_vectors[i]\n",
        "\n",
        "            neighbours = np.zeros(1)\n",
        "\n",
        "            manhattan_distances = np.zeros(train_x_len, np.float32)\n",
        "\n",
        "            for j in range(train_x_len):\n",
        "                \n",
        "                distance = manhattan_distance(x_test, train_feature_vector[j])\n",
        "\n",
        "                manhattan_distances[j] = distance\n",
        "\n",
        "            inds = manhattan_distances.argsort() \n",
        "          \n",
        "            Y_train_sorted = train_labels[inds] \n",
        "\n",
        "            neighbours = Y_train_sorted[0]\n",
        "\n",
        "\n",
        "            y_predict[i] = neighbours\n",
        "\n",
        "    elif metric == \"Chi-Squared\":\n",
        "         for i in range(test_x_len):\n",
        "\n",
        "            x_test = test_feature_vectors[i]\n",
        "\n",
        "            neighbours = np.zeros(1)\n",
        "\n",
        "            chi_squared_distances = np.zeros(train_x_len, np.float32)\n",
        "\n",
        "            for j in range(train_x_len):\n",
        "                \n",
        "                distance = chi_squared_distance(x_test, train_feature_vector[j])\n",
        "\n",
        "                chi_squared_distances[j] = distance\n",
        "\n",
        "            inds = chi_squared_distances.argsort() \n",
        "          \n",
        "            Y_train_sorted = train_labels[inds] \n",
        "\n",
        "            neighbours = Y_train_sorted[0]\n",
        "\n",
        "\n",
        "            y_predict[i] = neighbours\n",
        "\n",
        "    elif metric == \"Mahalanobis\":\n",
        "        \n",
        "        inv_cov_matrix = compute_inverse_covariance_matrix(train_feature_vector)\n",
        "\n",
        "        for i in range(test_x_len):\n",
        "\n",
        "            x_test = test_feature_vectors[i]\n",
        "\n",
        "            neighbours = np.zeros(1)\n",
        "\n",
        "            mahalanobis_distances = np.zeros(train_x_len, np.float32)\n",
        "\n",
        "            for j in range(train_x_len):\n",
        "                \n",
        "                distance = mahalanobis_distance(x_test, train_feature_vector[j], inv_cov_matrix)\n",
        "\n",
        "                mahalanobis_distances[j] = distance\n",
        "\n",
        "            inds = mahalanobis_distances.argsort() \n",
        "          \n",
        "            Y_train_sorted = train_labels[inds] \n",
        "\n",
        "            neighbours = Y_train_sorted[0]\n",
        "\n",
        "            y_predict[i] = neighbours\n",
        "    \n",
        "    else:\n",
        "        raise Exception(f\"{metric} distance metric is not supported by this implementation\")\n",
        "    \n",
        "    return y_predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 0  0  0 ... 23 23 23]\n"
          ]
        }
      ],
      "source": [
        "# labels\n",
        "\n",
        "train_labels = []\n",
        "\n",
        "with open('imageset/000/train.txt') as f:\n",
        "    labels = f.readlines()\n",
        "    for line in labels[1:]:\n",
        "        _, label = line.split()\n",
        "        label = label.strip()\n",
        "        train_labels.append(int(label))\n",
        "\n",
        "train_labels = np.array(train_labels)\n",
        "\n",
        "\n",
        "test0_labels = []\n",
        "\n",
        "with open('test1.txt') as f:\n",
        "    labels = f.readlines()\n",
        "    for line in labels[1:]:\n",
        "        _, label = line.split()\n",
        "        label = label.strip()\n",
        "        test0_labels.append(int(label))\n",
        "\n",
        "test0_labels = np.array(test0_labels)\n",
        "\n",
        "\n",
        "test1_labels = []\n",
        "\n",
        "with open('test2.txt') as f:\n",
        "    labels = f.readlines()\n",
        "    for line in labels[1:]:\n",
        "        _, label = line.split()\n",
        "        label = label.strip()\n",
        "        test1_labels.append(int(label))\n",
        "\n",
        "test1_labels = np.array(test1_labels)\n",
        "\n",
        "print(test0_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluation Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def evaluate_classification(true_labels, predicted_labels):\n",
        "    \"\"\"\n",
        "    Evaluate classification accuracy.\n",
        "    \n",
        "    Args:\n",
        "        true_labels: Ground truth labels.\n",
        "        predicted_labels: Predicted labels.\n",
        "\n",
        "    Returns:\n",
        "        Accuracy score.\n",
        "    \"\"\"\n",
        "    return accuracy_score(true_labels, predicted_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## All metrics with all features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_results(train, train_labels, test_0_dict, test_0_labels, test_1_dict, test_1_labels):\n",
        "\n",
        "    distance_metrics = [\"Euclidean\", \"Manhattan\", \"Chi-Squared\", \"Mahalanobis\"]\n",
        "    feature_types = [\"LBP\", \"GLCM\", \"FFT\", \"Gabor\"]\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    for feature in feature_types:\n",
        "\n",
        "        for metric in distance_metrics:\n",
        "            test0_predict = nearest_neighbour(train[feature], train_labels, test_0_dict[feature], metric=metric)\n",
        "            test1_predict = nearest_neighbour(train[feature], train_labels, test_1_dict[feature], metric=metric)\n",
        "\n",
        "            accuracy_test0 = evaluate_classification(test0_predict, test_0_labels)\n",
        "            accuracy_test1 = evaluate_classification(test1_predict, test_1_labels)\n",
        "\n",
        "            results[f\"{feature} - {metric}\"] = {\n",
        "                \"Test 0 Accuracy\": accuracy_test0,\n",
        "                \"Test 1 Accuracy\": accuracy_test1\n",
        "            }\n",
        "    results = pd.DataFrame(results).T\n",
        "\n",
        "    return results\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Test 0 Accuracy</th>\n",
              "      <th>Test 1 Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>LBP - Euclidean</th>\n",
              "      <td>0.639352</td>\n",
              "      <td>0.618981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LBP - Manhattan</th>\n",
              "      <td>0.642593</td>\n",
              "      <td>0.605093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LBP - Chi-Squared</th>\n",
              "      <td>0.665278</td>\n",
              "      <td>0.652083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LBP - Mahalanobis</th>\n",
              "      <td>0.695833</td>\n",
              "      <td>0.710185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GLCM - Euclidean</th>\n",
              "      <td>0.240046</td>\n",
              "      <td>0.219444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GLCM - Manhattan</th>\n",
              "      <td>0.255324</td>\n",
              "      <td>0.236806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GLCM - Chi-Squared</th>\n",
              "      <td>0.357870</td>\n",
              "      <td>0.340741</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GLCM - Mahalanobis</th>\n",
              "      <td>0.447685</td>\n",
              "      <td>0.499537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FFT - Euclidean</th>\n",
              "      <td>0.647917</td>\n",
              "      <td>0.614352</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FFT - Manhattan</th>\n",
              "      <td>0.644213</td>\n",
              "      <td>0.617824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FFT - Chi-Squared</th>\n",
              "      <td>0.617361</td>\n",
              "      <td>0.580093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FFT - Mahalanobis</th>\n",
              "      <td>0.502546</td>\n",
              "      <td>0.518981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Gabor - Euclidean</th>\n",
              "      <td>0.293981</td>\n",
              "      <td>0.290278</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Gabor - Manhattan</th>\n",
              "      <td>0.291435</td>\n",
              "      <td>0.293287</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Gabor - Chi-Squared</th>\n",
              "      <td>0.292593</td>\n",
              "      <td>0.291435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Gabor - Mahalanobis</th>\n",
              "      <td>0.266435</td>\n",
              "      <td>0.277546</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     Test 0 Accuracy  Test 1 Accuracy\n",
              "LBP - Euclidean             0.639352         0.618981\n",
              "LBP - Manhattan             0.642593         0.605093\n",
              "LBP - Chi-Squared           0.665278         0.652083\n",
              "LBP - Mahalanobis           0.695833         0.710185\n",
              "GLCM - Euclidean            0.240046         0.219444\n",
              "GLCM - Manhattan            0.255324         0.236806\n",
              "GLCM - Chi-Squared          0.357870         0.340741\n",
              "GLCM - Mahalanobis          0.447685         0.499537\n",
              "FFT - Euclidean             0.647917         0.614352\n",
              "FFT - Manhattan             0.644213         0.617824\n",
              "FFT - Chi-Squared           0.617361         0.580093\n",
              "FFT - Mahalanobis           0.502546         0.518981\n",
              "Gabor - Euclidean           0.293981         0.290278\n",
              "Gabor - Manhattan           0.291435         0.293287\n",
              "Gabor - Chi-Squared         0.292593         0.291435\n",
              "Gabor - Mahalanobis         0.266435         0.277546"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "initial_result = pd.DataFrame(results).T\n",
        "initial_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Combinations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_combinations_result(train, train_labels, test_0_dict, test_0_labels, test_1_dict, test_1_labels):\n",
        "\n",
        "    distance_metrics = [\"Euclidean\", \"Manhattan\", \"Chi-Squared\", \"Mahalanobis\"]\n",
        "    feature_types = [\"LBP\", \"GLCM\", \"FFT\", \"Gabor\"]\n",
        "\n",
        "    combination_results = {}\n",
        "\n",
        "    for feature1 in feature_types:\n",
        "        for feature2 in feature_types:\n",
        "            for metric in distance_metrics:\n",
        "\n",
        "                combined_train_features = np.concatenate((train[feature1], train[feature2]), axis=1)\n",
        "                combined_test0_features = np.concatenate((test_0_dict[feature1], test_0_dict[feature2]), axis=1)\n",
        "                combined_test1_features = np.concatenate((test_1_dict[feature1], test_1_dict[feature2]), axis=1)\n",
        "\n",
        "                test0_predict = nearest_neighbour(combined_train_features, train_labels, combined_test0_features, metric=metric)\n",
        "                test1_predict = nearest_neighbour(combined_train_features, train_labels, combined_test1_features, metric=metric)\n",
        "\n",
        "                accuracy_test0 = evaluate_classification(test0_predict, test_0_labels)\n",
        "                accuracy_test1 = evaluate_classification(test1_predict, test_1_labels)\n",
        "\n",
        "                combination_results[f\"{feature1}\"] = {\"feature2\": feature2, \"metric\" : metric, \"Test 0 Accuracy\": accuracy_test0, \"Test 1 Accuracy\": accuracy_test1}\n",
        "\n",
        "    combination_results = pd.DataFrame(combination_results).T\n",
        "    return combination_results "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "\n",
        "def calculate_combinations_result_scikit(train, train_labels, test_0_dict, test_0_labels, test_1_dict, test_1_labels):\n",
        "\n",
        "    distance_metrics = [\"euclidean\", \"manhattan\", \"mahalanobis\"]\n",
        "    feature_types = [\"LBP\", \"GLCM\", \"FFT\", \"Gabor\"]\n",
        "\n",
        "    combination_results = {}\n",
        "\n",
        "    for feature1 in feature_types:\n",
        "        for feature2 in feature_types:\n",
        "            if feature1 != feature2:\n",
        "\n",
        "                combined_train_features = np.concatenate((train[feature1], train[feature2]), axis=1)\n",
        "                combined_test0_features = np.concatenate((test_0_dict[feature1], test_0_dict[feature2]), axis=1)\n",
        "                combined_test1_features = np.concatenate((test_1_dict[feature1], test_1_dict[feature2]), axis=1)\n",
        "                \n",
        "                for metric in distance_metrics:\n",
        "                    if metric == \"mahalanobis\":\n",
        "                        model1 = KNeighborsClassifier(n_neighbors=1, metric=metric, metric_params={'VI': np.cov(combined_train_features.T)})\n",
        "                    else:\n",
        "                        model1 = KNeighborsClassifier(n_neighbors=1, metric=metric)\n",
        "                    model1.fit(combined_train_features, train_labels)\n",
        "                    test0_predict = model1.predict(combined_test0_features)\n",
        "                    test1_predict = model1.predict(combined_test1_features)\n",
        "\n",
        "                    \"\"\"test0_predict = nearest_neighbour(combined_train_features, train_labels, combined_test0_features, metric=metric)\n",
        "                    test1_predict = nearest_neighbour(combined_train_features, train_labels, combined_test1_features, metric=metric)\"\"\"\n",
        "\n",
        "                    accuracy_test0 = evaluate_classification(test0_predict, test_0_labels)\n",
        "                    accuracy_test1 = evaluate_classification(test1_predict, test_1_labels)\n",
        "\n",
        "                    combination_results[f\"{feature1} - {feature2} - {metric}\"] = {\"Test 0 Accuracy\": accuracy_test0, \"Test 1 Accuracy\": accuracy_test1}\n",
        "            print(1)\n",
        "\n",
        "    print(combination_results)\n",
        "\n",
        "    combination_results = pd.DataFrame(combination_results).T\n",
        "    return combination_results "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature2</th>\n",
              "      <th>metric</th>\n",
              "      <th>Test 0 Accuracy</th>\n",
              "      <th>Test 1 Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>LBP</th>\n",
              "      <td>Gabor</td>\n",
              "      <td>Mahalanobis</td>\n",
              "      <td>0.515972</td>\n",
              "      <td>0.543287</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GLCM</th>\n",
              "      <td>Gabor</td>\n",
              "      <td>Mahalanobis</td>\n",
              "      <td>0.399074</td>\n",
              "      <td>0.425926</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FFT</th>\n",
              "      <td>FFT</td>\n",
              "      <td>Chi-Squared</td>\n",
              "      <td>0.617361</td>\n",
              "      <td>0.580093</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     feature2       metric Test 0 Accuracy Test 1 Accuracy\n",
              "LBP     Gabor  Mahalanobis        0.515972        0.543287\n",
              "GLCM    Gabor  Mahalanobis        0.399074        0.425926\n",
              "FFT       FFT  Chi-Squared        0.617361        0.580093"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "combination_results = pd.DataFrame(combination_results).T\n",
        "combination_results "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "result= nearest_neighbour(train[\"Gabor\"], train_labels, test_0_dict[\"Gabor\"], metric=\"Euclidean\")\n",
        "print(evaluate_classification(test0_labels, result))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(480, 23)\n",
            "(4320, 23)\n"
          ]
        }
      ],
      "source": [
        "comb = np.concatenate((train[\"LBP\"], train[\"FFT\"]), axis=1)\n",
        "print(comb.shape)\n",
        "test0_comb = np.concatenate((test_0_dict[\"LBP\"], test_0_dict[\"FFT\"]), axis=1)\n",
        "print(test0_comb.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.6442129629629629\n"
          ]
        }
      ],
      "source": [
        "result_comb = nearest_neighbour(comb, train_labels, test0_comb, metric=\"Manhattan\")\n",
        "print(evaluate_classification(test0_labels, result_comb))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for key, value in results.items():\n",
        "    print(key, value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.6479166666666667\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "model = KNeighborsClassifier(n_neighbors=1, metric='mahalanobis', metric_params={'VI': np.cov(comb.T)})\n",
        "\n",
        "model.fit(comb, train_labels)\n",
        "\n",
        "res = model.predict(test0_comb)\n",
        "\n",
        "\n",
        "print(evaluate_classification(test0_labels, res))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def gabor_larger_image_bank(image, ksize_list=[7, 11, 15, 21], sigma_=[2.0, 3.0, 4.0], \n",
        "                            lambd_=[4, 8, 16], gamma=0.5, psi=0, orientations=None):\n",
        "    \"\"\"\n",
        "    Extract flattened Gabor features from an image using multiple kernel sizes, orientations, sigma, and wavelengths.\n",
        "\n",
        "    Args:\n",
        "        image (np.ndarray): Grayscale input image.\n",
        "        ksize_list (list): List of kernel sizes for the Gabor filter.\n",
        "        sigma_ (list): List of standard deviations of the Gaussian envelope.\n",
        "        lambd_ (list): List of wavelengths of the sinusoidal factor.\n",
        "        gamma (float): Aspect ratio.\n",
        "        psi (float): Phase offset.\n",
        "        orientations (list): List of orientations in radians. Defaults to [0, π/4, π/2, 3π/4].\n",
        "\n",
        "    Returns:\n",
        "        gabor_features (np.ndarray): Flattened feature vector (mean and std for each configuration).\n",
        "        filtered_images (list): List of filtered images for each configuration.\n",
        "        kernels (list): List of Gabor filter kernels for each configuration.\n",
        "    \"\"\"\n",
        "    if orientations is None:\n",
        "        orientations = [0, np.pi / 8, np.pi / 4, 3 * np.pi / 8, np.pi / 2, \n",
        "                        5 * np.pi / 8, 3 * np.pi / 4, 7 * np.pi / 8]  # Default orientations\n",
        "\n",
        "    # Lists to store results\n",
        "    filtered_images = []\n",
        "    kernels = []\n",
        "    gabor_features = []\n",
        "\n",
        "    # Iterate through all combinations of kernel sizes, sigma, lambd, and orientations\n",
        "    for ksize in ksize_list:\n",
        "        for theta in orientations:\n",
        "            for sigma in sigma_:\n",
        "                for lambd in lambd_:\n",
        "                    # Create Gabor kernel\n",
        "                    kernel = cv2.getGaborKernel((ksize, ksize), sigma, theta, lambd, gamma, psi, ktype=cv2.CV_32F)\n",
        "                    \n",
        "                    # Apply Gabor filter to the image\n",
        "                    filtered = cv2.filter2D(image, cv2.CV_8UC3, kernel)\n",
        "                    \n",
        "                    # Calculate mean and standard deviation as features\n",
        "                    mean = filtered.mean()\n",
        "                    std = filtered.std()\n",
        "                    gabor_features.append(mean)\n",
        "                    gabor_features.append(std)\n",
        "                    \n",
        "                    # Store the filtered image and kernel\n",
        "                    filtered_images.append(filtered)\n",
        "                    kernels.append(kernel)\n",
        "\n",
        "    # Flatten the feature vector\n",
        "    gabor_features = np.array(gabor_features)\n",
        "\n",
        "    return gabor_features, filtered_images, kernels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[11], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m new_gabor_test1 \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m train_0:\n\u001b[0;32m----> 7\u001b[0m     flattened_features, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mgabor_larger_image_bank\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     new_gabor_train\u001b[38;5;241m.\u001b[39mappend(flattened_features)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m test_0:\n",
            "Cell \u001b[0;32mIn[10], line 41\u001b[0m, in \u001b[0;36mgabor_larger_image_bank\u001b[0;34m(image, ksize_list, sigma_, lambd_, gamma, psi, orientations)\u001b[0m\n\u001b[1;32m     38\u001b[0m kernel \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mgetGaborKernel((ksize, ksize), sigma, theta, lambd, gamma, psi, ktype\u001b[38;5;241m=\u001b[39mcv2\u001b[38;5;241m.\u001b[39mCV_32F)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Apply Gabor filter to the image\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m filtered \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter2D\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCV_8UC3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Calculate mean and standard deviation as features\u001b[39;00m\n\u001b[1;32m     44\u001b[0m mean \u001b[38;5;241m=\u001b[39m filtered\u001b[38;5;241m.\u001b[39mmean()\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "new_gabor_train = []\n",
        "new_gabor_test0 = []\n",
        "new_gabor_test1 = []\n",
        "\n",
        "\n",
        "for image in train_0:\n",
        "    flattened_features, _, _ = gabor_larger_image_bank(image)\n",
        "    new_gabor_train.append(flattened_features)\n",
        "\n",
        "for image in test_0:\n",
        "    flattened_features, _, _ = gabor_larger_image_bank(image)\n",
        "    new_gabor_test0.append(flattened_features)\n",
        "\n",
        "for image in test_1:\n",
        "    flattened_features, _, _ = gabor_larger_image_bank(image)\n",
        "    new_gabor_test1.append(flattened_features)\n",
        "\n",
        "new_gabor_train = np.array(new_gabor_train)\n",
        "new_gabor_test0 = np.array(new_gabor_test0)\n",
        "new_gabor_test1 = np.array(new_gabor_test1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.47939814814814813\n"
          ]
        }
      ],
      "source": [
        "new_Result = nearest_neighbour(new_gabor_train, train_labels, new_gabor_test0, metric=\"Euclidean\")\n",
        "print(evaluate_classification(test0_labels, new_Result))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(4320, 576)\n"
          ]
        }
      ],
      "source": [
        "print(new_gabor_test0.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize dictionaries to store feature vectors for training and test sets\n",
        "train_2 = {}\n",
        "test_0_dict_2 = {}\n",
        "test_1_dict_2 = {}\n",
        "\n",
        "# Define distances and angles for GLCM computation\n",
        "distances = [1, 2, 3, 5]  # Fine and coarse distances\n",
        "angles = [0, np.pi/8, np.pi/4, 3*np.pi/8, np.pi/2, 5*np.pi/8, 3*np.pi/4, 7*np.pi/8]\n",
        "\n",
        "# Initialize lists to store feature vectors\n",
        "lbp_ = []\n",
        "glcm_ = []\n",
        "fft_ = []\n",
        "gabor_ = []\n",
        "\n",
        "# Compute features for training images\n",
        "for image in train_0:\n",
        "    lbp_.append(compute_lbp(image))  # Compute LBP features\n",
        "    _, image_features = compute_glcm_features(image, distances, angles)\n",
        "    glcm_.append(image_features)  # Compute GLCM features\n",
        "    fft_.append(compute_fft_features(image, 8, 12))  # Compute FFT features\n",
        "    flattened_features, _, _ = gabor_larger_image_bank(image)  # Compute Gabor features\n",
        "    gabor_.append(flattened_features)  # Compute Gabor features\n",
        "\n",
        "# Store computed features in the training dictionary\n",
        "train_2[\"LBP\"] = np.array(lbp_)\n",
        "train_2[\"GLCM\"] = np.array(glcm_)\n",
        "train_2[\"FFT\"] = np.array(fft_)\n",
        "train_2[\"Gabor\"] = np.array(gabor_)\n",
        "\n",
        "# Reset feature lists for test_0\n",
        "lbp0_ = []\n",
        "glcm0_ = []\n",
        "fft0_ = []\n",
        "gabor0_ = []\n",
        "\n",
        "# Compute features for test_0 images\n",
        "for i, image in enumerate(test_0):\n",
        "    lbp0_.append(compute_lbp(image))  # Compute LBP features\n",
        "    _, image_features = compute_glcm_features(image, distances, angles)\n",
        "    glcm0_.append(image_features)  # Compute GLCM features\n",
        "    fft0_.append(compute_fft_features(image, 8, 12))  # Compute FFT features\n",
        "    flattened_features, _, _ = gabor_larger_image_bank(image)  # Compute Gabor features\n",
        "    gabor0_.append(flattened_features)  # Compute Gabor features\n",
        "\n",
        "# Store computed features in the test_0 dictionary\n",
        "test_0_dict_2[\"LBP\"] = np.array(lbp0_)\n",
        "test_0_dict_2[\"GLCM\"] = np.array(glcm0_)\n",
        "test_0_dict_2[\"FFT\"] = np.array(fft0_)\n",
        "test_0_dict_2[\"Gabor\"] = np.array(gabor0_)\n",
        "\n",
        "# Reset feature lists for test_1\n",
        "lbp1_ = []\n",
        "glcm1_ = []\n",
        "fft1_ = []\n",
        "gabor1_ = []\n",
        "\n",
        "# Compute features for test_1 images\n",
        "for image in test_1:\n",
        "    lbp1_.append(compute_lbp(image))  # Compute LBP features\n",
        "    _, image_features = compute_glcm_features(image, distances, angles)\n",
        "    glcm1_.append(image_features)  # Compute GLCM features\n",
        "    fft1_.append(compute_fft_features(image, 8, 12))  # Compute FFT features\n",
        "    flattened_features, _, _ = gabor_larger_image_bank(image)  # Compute Gabor features\n",
        "    gabor1_.append(flattened_features)  # Compute Gabor features\n",
        "\n",
        "# Store computed features in the test_1 dictionary\n",
        "test_1_dict_2[\"LBP\"] = np.array(lbp1_)\n",
        "test_1_dict_2[\"GLCM\"] = np.array(glcm1_)\n",
        "test_1_dict_2[\"FFT\"] = np.array(fft1_)\n",
        "test_1_dict_2[\"Gabor\"] = np.array(gabor1_)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Shapes:\n",
            "Training set: (480, 18), (480, 5), (480, 20), (480, 576)\n",
            "Test set 0: (4320, 18), (4320, 5), (4320, 20), (4320, 576)\n",
            "Test set 1: (4320, 18), (4320, 5), (4320, 20), (4320, 576)\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nShapes:\")\n",
        "print(f\"Training set: {train_2['LBP'].shape}, {train_2['GLCM'].shape}, {train_2['FFT'].shape}, {train_2['Gabor'].shape}\")\n",
        "print(f\"Test set 0: {test_0_dict_2['LBP'].shape}, {test_0_dict_2['GLCM'].shape}, {test_0_dict_2['FFT'].shape}, {test_0_dict_2['Gabor'].shape}\")\n",
        "print(f\"Test set 1: {test_1_dict_2['LBP'].shape}, {test_1_dict_2['GLCM'].shape}, {test_1_dict_2['FFT'].shape}, {test_1_dict_2['Gabor'].shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Test 0 Accuracy</th>\n",
              "      <th>Test 1 Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>LBP - Euclidean</th>\n",
              "      <td>0.639352</td>\n",
              "      <td>0.618981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LBP - Manhattan</th>\n",
              "      <td>0.642593</td>\n",
              "      <td>0.605093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LBP - Chi-Squared</th>\n",
              "      <td>0.665278</td>\n",
              "      <td>0.652083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LBP - Mahalanobis</th>\n",
              "      <td>0.695833</td>\n",
              "      <td>0.710185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GLCM - Euclidean</th>\n",
              "      <td>0.240046</td>\n",
              "      <td>0.219444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GLCM - Manhattan</th>\n",
              "      <td>0.255324</td>\n",
              "      <td>0.236806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GLCM - Chi-Squared</th>\n",
              "      <td>0.357870</td>\n",
              "      <td>0.340741</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GLCM - Mahalanobis</th>\n",
              "      <td>0.447685</td>\n",
              "      <td>0.499537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FFT - Euclidean</th>\n",
              "      <td>0.686574</td>\n",
              "      <td>0.679630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FFT - Manhattan</th>\n",
              "      <td>0.686806</td>\n",
              "      <td>0.683565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FFT - Chi-Squared</th>\n",
              "      <td>0.638426</td>\n",
              "      <td>0.625231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FFT - Mahalanobis</th>\n",
              "      <td>0.468287</td>\n",
              "      <td>0.498148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Gabor - Euclidean</th>\n",
              "      <td>0.479398</td>\n",
              "      <td>0.473611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Gabor - Manhattan</th>\n",
              "      <td>0.489583</td>\n",
              "      <td>0.485185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Gabor - Chi-Squared</th>\n",
              "      <td>0.488194</td>\n",
              "      <td>0.486806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Gabor - Mahalanobis</th>\n",
              "      <td>0.345602</td>\n",
              "      <td>0.329861</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     Test 0 Accuracy  Test 1 Accuracy\n",
              "LBP - Euclidean             0.639352         0.618981\n",
              "LBP - Manhattan             0.642593         0.605093\n",
              "LBP - Chi-Squared           0.665278         0.652083\n",
              "LBP - Mahalanobis           0.695833         0.710185\n",
              "GLCM - Euclidean            0.240046         0.219444\n",
              "GLCM - Manhattan            0.255324         0.236806\n",
              "GLCM - Chi-Squared          0.357870         0.340741\n",
              "GLCM - Mahalanobis          0.447685         0.499537\n",
              "FFT - Euclidean             0.686574         0.679630\n",
              "FFT - Manhattan             0.686806         0.683565\n",
              "FFT - Chi-Squared           0.638426         0.625231\n",
              "FFT - Mahalanobis           0.468287         0.498148\n",
              "Gabor - Euclidean           0.479398         0.473611\n",
              "Gabor - Manhattan           0.489583         0.485185\n",
              "Gabor - Chi-Squared         0.488194         0.486806\n",
              "Gabor - Mahalanobis         0.345602         0.329861"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "second_results = calculate_results(train_2, train_labels, test_0_dict_2, test0_labels, test_1_dict_2, test1_labels)\n",
        "second_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n",
            "1\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[39], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m second_comb_result \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_combinations_result_scikit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_0_dict_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest0_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_1_dict_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest1_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m second_comb_result\n",
            "Cell \u001b[0;32mIn[38], line 26\u001b[0m, in \u001b[0;36mcalculate_combinations_result_scikit\u001b[0;34m(train, train_labels, test_0_dict, test_0_labels, test_1_dict, test_1_labels)\u001b[0m\n\u001b[1;32m     24\u001b[0m model1\u001b[38;5;241m.\u001b[39mfit(combined_train_features, train_labels)\n\u001b[1;32m     25\u001b[0m test0_predict \u001b[38;5;241m=\u001b[39m model1\u001b[38;5;241m.\u001b[39mpredict(combined_test0_features)\n\u001b[0;32m---> 26\u001b[0m test1_predict \u001b[38;5;241m=\u001b[39m \u001b[43mmodel1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcombined_test1_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"test0_predict = nearest_neighbour(combined_train_features, train_labels, combined_test0_features, metric=metric)\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;124;03mtest1_predict = nearest_neighbour(combined_train_features, train_labels, combined_test1_features, metric=metric)\"\"\"\u001b[39;00m\n\u001b[1;32m     31\u001b[0m accuracy_test0 \u001b[38;5;241m=\u001b[39m evaluate_classification(test0_predict, test_0_labels)\n",
            "File \u001b[0;32m~/Desktop/CS419/Assignments/Assignment4/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py:274\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_[np\u001b[38;5;241m.\u001b[39margmax(probabilities, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)]\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;66;03m# In that case, we do not need the distances to perform\u001b[39;00m\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;66;03m# the weighting so we do not compute them.\u001b[39;00m\n\u001b[0;32m--> 274\u001b[0m     neigh_ind \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkneighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    275\u001b[0m     neigh_dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "File \u001b[0;32m~/Desktop/CS419/Assignments/Assignment4/.venv/lib/python3.12/site-packages/sklearn/neighbors/_base.py:905\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    903\u001b[0m         kwds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meffective_metric_params_\n\u001b[0;32m--> 905\u001b[0m     chunked_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    906\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpairwise_distances_chunked\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    907\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    908\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_X\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    909\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreduce_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreduce_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    910\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meffective_metric_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    911\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    912\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    913\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    914\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_method \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mball_tree\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkd_tree\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    917\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m issparse(X):\n",
            "File \u001b[0;32m~/Desktop/CS419/Assignments/Assignment4/.venv/lib/python3.12/site-packages/sklearn/metrics/pairwise.py:2252\u001b[0m, in \u001b[0;36mpairwise_distances_chunked\u001b[0;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[1;32m   2250\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2251\u001b[0m     X_chunk \u001b[38;5;241m=\u001b[39m X[sl]\n\u001b[0;32m-> 2252\u001b[0m D_chunk \u001b[38;5;241m=\u001b[39m \u001b[43mpairwise_distances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2253\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (X \u001b[38;5;129;01mis\u001b[39;00m Y \u001b[38;5;129;01mor\u001b[39;00m Y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m PAIRWISE_DISTANCE_FUNCTIONS\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   2254\u001b[0m     metric, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2255\u001b[0m ) \u001b[38;5;129;01mis\u001b[39;00m euclidean_distances:\n\u001b[1;32m   2256\u001b[0m     \u001b[38;5;66;03m# zeroing diagonal, taking care of aliases of \"euclidean\",\u001b[39;00m\n\u001b[1;32m   2257\u001b[0m     \u001b[38;5;66;03m# i.e. \"l2\"\u001b[39;00m\n\u001b[1;32m   2258\u001b[0m     D_chunk\u001b[38;5;241m.\u001b[39mflat[sl\u001b[38;5;241m.\u001b[39mstart :: _num_samples(X) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
            "File \u001b[0;32m~/Desktop/CS419/Assignments/Assignment4/.venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    214\u001b[0m         )\n\u001b[1;32m    215\u001b[0m     ):\n\u001b[0;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    226\u001b[0m     )\n",
            "File \u001b[0;32m~/Desktop/CS419/Assignments/Assignment4/.venv/lib/python3.12/site-packages/sklearn/metrics/pairwise.py:2480\u001b[0m, in \u001b[0;36mpairwise_distances\u001b[0;34m(X, Y, metric, n_jobs, force_all_finite, ensure_all_finite, **kwds)\u001b[0m\n\u001b[1;32m   2477\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m distance\u001b[38;5;241m.\u001b[39msquareform(distance\u001b[38;5;241m.\u001b[39mpdist(X, metric\u001b[38;5;241m=\u001b[39mmetric, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds))\n\u001b[1;32m   2478\u001b[0m     func \u001b[38;5;241m=\u001b[39m partial(distance\u001b[38;5;241m.\u001b[39mcdist, metric\u001b[38;5;241m=\u001b[39mmetric, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m-> 2480\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_parallel_pairwise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Desktop/CS419/Assignments/Assignment4/.venv/lib/python3.12/site-packages/sklearn/metrics/pairwise.py:1973\u001b[0m, in \u001b[0;36m_parallel_pairwise\u001b[0;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[1;32m   1970\u001b[0m X, Y, dtype \u001b[38;5;241m=\u001b[39m _return_float_dtype(X, Y)\n\u001b[1;32m   1972\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m effective_n_jobs(n_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m-> 1973\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1975\u001b[0m \u001b[38;5;66;03m# enforce a threading backend to prevent data communication overhead\u001b[39;00m\n\u001b[1;32m   1976\u001b[0m fd \u001b[38;5;241m=\u001b[39m delayed(_dist_wrapper)\n",
            "File \u001b[0;32m~/Desktop/CS419/Assignments/Assignment4/.venv/lib/python3.12/site-packages/scipy/spatial/distance.py:2980\u001b[0m, in \u001b[0;36mcdist\u001b[0;34m(XA, XB, metric, out, **kwargs)\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m metric_info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2979\u001b[0m     cdist_fn \u001b[38;5;241m=\u001b[39m metric_info\u001b[38;5;241m.\u001b[39mcdist_func\n\u001b[0;32m-> 2980\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcdist_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2981\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mstr\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   2982\u001b[0m     metric_info \u001b[38;5;241m=\u001b[39m _TEST_METRICS\u001b[38;5;241m.\u001b[39mget(mstr, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
            "File \u001b[0;32m~/Desktop/CS419/Assignments/Assignment4/.venv/lib/python3.12/site-packages/scipy/spatial/distance.py:1638\u001b[0m, in \u001b[0;36mCDistMetricWrapper.__call__\u001b[0;34m(self, XA, XB, out, **kwargs)\u001b[0m\n\u001b[1;32m   1636\u001b[0m \u001b[38;5;66;03m# get cdist wrapper\u001b[39;00m\n\u001b[1;32m   1637\u001b[0m cdist_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_distance_wrap, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcdist_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtyp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_wrap\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1638\u001b[0m \u001b[43mcdist_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1639\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dm\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "second_comb_result = calculate_combinations_result_scikit(train_2, train_labels, test_0_dict_2, test0_labels, test_1_dict_2, test1_labels)\n",
        "second_comb_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature2</th>\n",
              "      <th>metric</th>\n",
              "      <th>Test 0 Accuracy</th>\n",
              "      <th>Test 1 Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>LBP</th>\n",
              "      <td>Gabor</td>\n",
              "      <td>mahalanobis</td>\n",
              "      <td>0.446528</td>\n",
              "      <td>0.454167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GLCM</th>\n",
              "      <td>Gabor</td>\n",
              "      <td>mahalanobis</td>\n",
              "      <td>0.440509</td>\n",
              "      <td>0.435185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FFT</th>\n",
              "      <td>Gabor</td>\n",
              "      <td>mahalanobis</td>\n",
              "      <td>0.672454</td>\n",
              "      <td>0.619907</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Gabor</th>\n",
              "      <td>FFT</td>\n",
              "      <td>mahalanobis</td>\n",
              "      <td>0.672454</td>\n",
              "      <td>0.619907</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      feature2       metric Test 0 Accuracy Test 1 Accuracy\n",
              "LBP      Gabor  mahalanobis        0.446528        0.454167\n",
              "GLCM     Gabor  mahalanobis        0.440509        0.435185\n",
              "FFT      Gabor  mahalanobis        0.672454        0.619907\n",
              "Gabor      FFT  mahalanobis        0.672454        0.619907"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "second_comb_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Counter Measures Against Illumination Variations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(480, 128, 128) (4320, 128, 128) (4320, 128, 128)\n"
          ]
        }
      ],
      "source": [
        "def normalize_equalize(image):\n",
        "    \"\"\"\n",
        "    Normalize and equalize the input image.\n",
        "\n",
        "    Args:\n",
        "        image (np.ndarray): Grayscale input image.\n",
        "\n",
        "    Returns:\n",
        "        Normalized and equalized image.\n",
        "    \"\"\"\n",
        "    # Normalize the image\n",
        "    normalized = cv2.normalize(image, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
        "    \n",
        "    # Equalize the histogram\n",
        "    equalized = cv2.equalizeHist(normalized)\n",
        "    \n",
        "    return equalized\n",
        "\n",
        "norm_train = []\n",
        "\n",
        "norm_test_0 = []\n",
        "\n",
        "norm_test_1 = []\n",
        "\n",
        "for image in train_0:\n",
        "    norm_train.append(normalize_equalize(image))\n",
        "\n",
        "for image in test_0:\n",
        "    norm_test_0.append(normalize_equalize(image))\n",
        "\n",
        "for image in test_1:\n",
        "    norm_test_1.append(normalize_equalize(image))\n",
        "\n",
        "norm_train = np.array(norm_train)\n",
        "norm_test_0 = np.array(norm_test_0)\n",
        "norm_test_1 = np.array(norm_test_1)\n",
        "\n",
        "print(norm_train.shape, norm_test_0.shape, norm_test_1.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_vectors(train, test_0, test_1):\n",
        "    # Initialize dictionaries to store feature vectors for training and test sets\n",
        "    train_vector = {}\n",
        "    test_0_vector = {}\n",
        "    test_1_vector = {}\n",
        "\n",
        "    # Define distances and angles for GLCM computation\n",
        "    distances = [1, 2, 3, 5]  # Fine and coarse distances\n",
        "    angles = [0, np.pi/8, np.pi/4, 3*np.pi/8, np.pi/2, 5*np.pi/8, 3*np.pi/4, 7*np.pi/8]\n",
        "\n",
        "    # Initialize lists to store feature vectors\n",
        "    lbp_ = []\n",
        "    glcm_ = []\n",
        "    fft_ = []\n",
        "    gabor_ = []\n",
        "\n",
        "    # Compute features for training images\n",
        "    for image in train:\n",
        "        lbp_.append(compute_lbp(image))  # Compute LBP features\n",
        "        _, image_features = compute_glcm_features(image, distances, angles)\n",
        "        glcm_.append(image_features)  # Compute GLCM features\n",
        "        fft_.append(compute_fft_features(image, 8, 12))  # Compute FFT features\n",
        "        flattened_features, _, _ = gabor_larger_image_bank(image)  # Compute Gabor features\n",
        "        gabor_.append(flattened_features)  # Compute Gabor features\n",
        "\n",
        "    # Store computed features in the training dictionary\n",
        "    train_vector[\"LBP\"] = np.array(lbp_)\n",
        "    train_vector[\"GLCM\"] = np.array(glcm_)\n",
        "    train_vector[\"FFT\"] = np.array(fft_)\n",
        "    train_vector[\"Gabor\"] = np.array(gabor_)\n",
        "\n",
        "    # Reset feature lists for test_0\n",
        "    lbp0_ = []\n",
        "    glcm0_ = []\n",
        "    fft0_ = []\n",
        "    gabor0_ = []\n",
        "\n",
        "    # Compute features for test_0 images\n",
        "    for i, image in enumerate(test_0):\n",
        "        lbp0_.append(compute_lbp(image))  # Compute LBP features\n",
        "        _, image_features = compute_glcm_features(image, distances, angles)\n",
        "        glcm0_.append(image_features)  # Compute GLCM features\n",
        "        fft0_.append(compute_fft_features(image, 8, 12))  # Compute FFT features\n",
        "        flattened_features, _, _ = gabor_larger_image_bank(image)  # Compute Gabor features\n",
        "        gabor0_.append(flattened_features)  # Compute Gabor features\n",
        "\n",
        "    # Store computed features in the test_0 dictionary\n",
        "    test_0_vector[\"LBP\"] = np.array(lbp0_)\n",
        "    test_0_vector[\"GLCM\"] = np.array(glcm0_)\n",
        "    test_0_vector[\"FFT\"] = np.array(fft0_)\n",
        "    test_0_vector[\"Gabor\"] = np.array(gabor0_)\n",
        "\n",
        "    # Reset feature lists for test_1\n",
        "    lbp1_ = []\n",
        "    glcm1_ = []\n",
        "    fft1_ = []\n",
        "    gabor1_ = []\n",
        "\n",
        "    # Compute features for test_1 images\n",
        "    for image in test_1:\n",
        "        lbp1_.append(compute_lbp(image))  # Compute LBP features\n",
        "        _, image_features = compute_glcm_features(image, distances, angles)\n",
        "        glcm1_.append(image_features)  # Compute GLCM features\n",
        "        fft1_.append(compute_fft_features(image, 8, 12))  # Compute FFT features\n",
        "        flattened_features, _, _ = gabor_larger_image_bank(image)  # Compute Gabor features\n",
        "        gabor1_.append(flattened_features)  # Compute Gabor features\n",
        "\n",
        "    # Store computed features in the test_1 dictionary\n",
        "    test_1_vector[\"LBP\"] = np.array(lbp1_)\n",
        "    test_1_vector[\"GLCM\"] = np.array(glcm1_)\n",
        "    test_1_vector[\"FFT\"] = np.array(fft1_)\n",
        "    test_1_vector[\"Gabor\"] = np.array(gabor1_)\n",
        "\n",
        "    return train_vector, test_0_vector, test_1_vector\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'calculate_results' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[29], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m train_vector, test_0_vector, test_1_vector \u001b[38;5;241m=\u001b[39m compute_vectors(norm_train, norm_test_0, norm_test_1)\n\u001b[0;32m----> 3\u001b[0m normalized_results \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_results\u001b[49m(train_vector, train_labels, test_0_vector, test0_labels, test_1_vector, test1_labels)\n\u001b[1;32m      5\u001b[0m normalized_results\n",
            "\u001b[0;31mNameError\u001b[0m: name 'calculate_results' is not defined"
          ]
        }
      ],
      "source": [
        "train_vector, test_0_vector, test_1_vector = compute_vectors(norm_train, norm_test_0, norm_test_1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Test 0 Accuracy</th>\n",
              "      <th>Test 1 Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>LBP - Euclidean</th>\n",
              "      <td>0.796991</td>\n",
              "      <td>0.708796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LBP - Manhattan</th>\n",
              "      <td>0.801157</td>\n",
              "      <td>0.724537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LBP - Chi-Squared</th>\n",
              "      <td>0.813889</td>\n",
              "      <td>0.757176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LBP - Mahalanobis</th>\n",
              "      <td>0.787269</td>\n",
              "      <td>0.815741</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GLCM - Euclidean</th>\n",
              "      <td>0.172685</td>\n",
              "      <td>0.153704</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GLCM - Manhattan</th>\n",
              "      <td>0.182639</td>\n",
              "      <td>0.163889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GLCM - Chi-Squared</th>\n",
              "      <td>0.258333</td>\n",
              "      <td>0.233102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GLCM - Mahalanobis</th>\n",
              "      <td>0.488657</td>\n",
              "      <td>0.503935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FFT - Euclidean</th>\n",
              "      <td>0.692593</td>\n",
              "      <td>0.673380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FFT - Manhattan</th>\n",
              "      <td>0.678241</td>\n",
              "      <td>0.662037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FFT - Chi-Squared</th>\n",
              "      <td>0.634259</td>\n",
              "      <td>0.618750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FFT - Mahalanobis</th>\n",
              "      <td>0.525694</td>\n",
              "      <td>0.546528</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Gabor - Euclidean</th>\n",
              "      <td>0.532407</td>\n",
              "      <td>0.536806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Gabor - Manhattan</th>\n",
              "      <td>0.553704</td>\n",
              "      <td>0.555787</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Gabor - Chi-Squared</th>\n",
              "      <td>0.545139</td>\n",
              "      <td>0.557407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Gabor - Mahalanobis</th>\n",
              "      <td>0.112269</td>\n",
              "      <td>0.106713</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     Test 0 Accuracy  Test 1 Accuracy\n",
              "LBP - Euclidean             0.796991         0.708796\n",
              "LBP - Manhattan             0.801157         0.724537\n",
              "LBP - Chi-Squared           0.813889         0.757176\n",
              "LBP - Mahalanobis           0.787269         0.815741\n",
              "GLCM - Euclidean            0.172685         0.153704\n",
              "GLCM - Manhattan            0.182639         0.163889\n",
              "GLCM - Chi-Squared          0.258333         0.233102\n",
              "GLCM - Mahalanobis          0.488657         0.503935\n",
              "FFT - Euclidean             0.692593         0.673380\n",
              "FFT - Manhattan             0.678241         0.662037\n",
              "FFT - Chi-Squared           0.634259         0.618750\n",
              "FFT - Mahalanobis           0.525694         0.546528\n",
              "Gabor - Euclidean           0.532407         0.536806\n",
              "Gabor - Manhattan           0.553704         0.555787\n",
              "Gabor - Chi-Squared         0.545139         0.557407\n",
              "Gabor - Mahalanobis         0.112269         0.106713"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "normalized_results = calculate_results(train_vector, train_labels, test_0_vector, test0_labels, test_1_vector, test1_labels)\n",
        "\n",
        "normalized_results "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
